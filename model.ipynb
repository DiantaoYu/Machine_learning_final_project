{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'dataset/train'\n",
    "valid_path = 'dataset/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8438 images belonging to 2 classes.\n",
      "Found 3051 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['hand','not_hand'], batch_size = 10)\n",
    "valid_batch = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['hand','not_hand'], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x1db7c078b38>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    cnn.add(layer)\n",
    "cnn.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in cnn.layers:\n",
    "    layer.trainable = False\n",
    "cnn.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 101s 127ms/step - loss: 0.0155 - acc: 0.9970 - val_loss: 0.0223 - val_acc: 0.9963\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0199 - val_acc: 0.9970\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.0031 - val_acc: 0.9987\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 8.2665e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9993\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 95s 118ms/step - loss: 0.0037 - acc: 0.9994 - val_loss: 0.0078 - val_acc: 0.9983\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 95s 118ms/step - loss: 8.1634e-06 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9990\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 95s 118ms/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0479 - val_acc: 0.9953\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 95s 118ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0097 - val_acc: 0.9980\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 95s 118ms/step - loss: 0.0070 - acc: 0.9992 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 95s 118ms/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0028 - val_acc: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db7c682da0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit_generator(train_batch, steps_per_epoch = 800, epochs = 10,\n",
    "               validation_data = valid_batch, validation_steps = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = image.load_img('333.jpg', target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = cnn.predict_classes(x, batch_size=10, verbose = 1)\n",
    "# print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open('333.jpg').resize((224,224))\n",
    "# x = np.array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# classes = cnn.predict_classes(x, batch_size=10, verbose = 1)\n",
    "# print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
